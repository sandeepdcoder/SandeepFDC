{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepdcoder/SandeepFDC/blob/main/Product_Review_using_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizing reviews based on user query semnatically with FAISS\n",
        "\n",
        "In this section, we'll demonstrate fetching reviews that are related to user query semantically.\n",
        "\n"
      ],
      "metadata": {
        "id": "BLqmBnUBLd58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "OqTtHTDyLoLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q faiss-cpu"
      ],
      "metadata": {
        "id": "JwGxr00vLwac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Make sure you have set the OPENAI_API_KEY environment variable\n",
        "# For Colab, you can use the \"🔑\" icon on the left panel to add your API key as a secret.\n",
        "# Name the secret OPENAI_API_KEY.\n",
        "# If you are running this outside of Colab, you can set it as an environment variable\n",
        "# in your terminal: export OPENAI_API_KEY='your-api-key'\n",
        "# Or you can uncomment the line below and replace 'your-api-key' with your actual key:\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-api-key'\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key= userdata.get('API_KEY'),\n",
        ")\n",
        "\n",
        "model = \"openai/gpt-4o-mini\" #\"gpt-4.1-mini-2025-04-14\"\n",
        "\n",
        "def generate_response(prompt, model=model, max_tokens=150):\n",
        "    \"\"\"\n",
        "    Generates a response from the OpenAI API.\n",
        "\n",
        "    Args:\n",
        "        prompt: The input prompt for the model.\n",
        "        model: The OpenAI model to use (default: \"gpt-3.5-turbo\").\n",
        "        max_tokens: The maximum number of tokens in the generated response.\n",
        "\n",
        "    Returns:\n",
        "        The text of the generated response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=0.7, # You can adjust the temperature\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "# Generate 200 diverse product reviews\n",
        "import random\n",
        "\n",
        "def generate_product_reviews(count=200):\n",
        "    \"\"\"Generate diverse product reviews for different products with varied sentiments\"\"\"\n",
        "\n",
        "    products = [\"smartphone\"] #[\"vacuum cleaner\", \"smartphone\", \"laptop\", \"headphones\", \"smartwatch\", \"tablet\", \"camera\", \"speaker\", \"fitness tracker\", \"e-reader\"]\n",
        "\n",
        "    positive_templates = [\n",
        "        \"This {product} is absolutely amazing! The {feature1} is outstanding and the {feature2} exceeded my expectations. {emotion} Highly recommended!\",\n",
        "        \"I'm incredibly impressed with this {product}. The {feature1} works flawlessly and {feature2} is top-notch. {emotion} Worth every penny!\",\n",
        "        \"Love this {product}! {feature1} is excellent, {feature2} is perfect, and the overall quality is superb. {emotion}\",\n",
        "        \"Best {product} I've ever owned! The {feature1} is incredible and {feature2} makes it even better. {emotion} Five stars!\",\n",
        "        \"This {product} has exceeded all my expectations. {feature1} is fantastic, {feature2} is great. {emotion} Couldn't be happier!\",\n",
        "    ]\n",
        "\n",
        "    negative_templates = [\n",
        "        \"Very disappointed with this {product}. The {feature1} is terrible and {feature2} doesn't work properly. {emotion} Would not recommend.\",\n",
        "        \"This {product} is a waste of money. {feature1} failed after a week and {feature2} is subpar. {emotion} Returning immediately.\",\n",
        "        \"Absolutely frustrated with this {product}. The {feature1} is unreliable and {feature2} is poor quality. {emotion} Avoid this product!\",\n",
        "        \"Terrible {product}. {feature1} doesn't meet expectations and {feature2} is disappointing. {emotion} Save your money.\",\n",
        "        \"This {product} is a complete letdown. {feature1} broke quickly and {feature2} never worked right. {emotion} Worst purchase ever!\",\n",
        "    ]\n",
        "\n",
        "    neutral_templates = [\n",
        "        \"This {product} is okay. The {feature1} is decent and {feature2} is average. {emotion} It works but nothing special.\",\n",
        "        \"Mixed feelings about this {product}. {feature1} is good but {feature2} could be better. {emotion} Acceptable for the price.\",\n",
        "        \"The {product} does what it's supposed to. {feature1} is fine, {feature2} is mediocre. {emotion} It's alright.\",\n",
        "        \"Average {product}. {feature1} works as expected, {feature2} is neither great nor terrible. {emotion} Could be better.\",\n",
        "        \"This {product} has pros and cons. {feature1} is satisfactory but {feature2} needs improvement. {emotion} Decent option.\",\n",
        "    ]\n",
        "\n",
        "    features = {\n",
        "        \"battery life\": [\"battery life\", \"charging speed\", \"power management\"],\n",
        "        \"performance\": [\"performance\", \"speed\", \"processing power\"],\n",
        "        \"design\": [\"design\", \"build quality\", \"aesthetics\"],\n",
        "        \"sound\": [\"sound quality\", \"audio clarity\", \"bass response\"],\n",
        "        \"display\": [\"display quality\", \"screen brightness\", \"resolution\"],\n",
        "        \"camera\": [\"camera quality\", \"photo clarity\", \"video recording\"],\n",
        "        \"durability\": [\"durability\", \"build material\", \"longevity\"],\n",
        "        \"price\": [\"value for money\", \"pricing\", \"cost-effectiveness\"],\n",
        "        \"features\": [\"features\", \"functionality\", \"capabilities\"],\n",
        "        \"connectivity\": [\"connectivity\", \"wireless connection\", \"Bluetooth\"]\n",
        "    }\n",
        "\n",
        "    emotions_positive = [\n",
        "        \"I'm so happy with this purchase!\",\n",
        "        \"Couldn't be more satisfied!\",\n",
        "        \"This has changed my life!\",\n",
        "        \"I'm telling everyone about this!\",\n",
        "        \"Best decision ever!\"\n",
        "    ]\n",
        "\n",
        "    emotions_negative = [\n",
        "        \"I'm extremely upset.\",\n",
        "        \"So frustrated with this!\",\n",
        "        \"I feel ripped off.\",\n",
        "        \"This ruined my day.\",\n",
        "        \"Never buying from this brand again!\"\n",
        "    ]\n",
        "\n",
        "    emotions_neutral = [\n",
        "        \"It's what I expected.\",\n",
        "        \"Nothing to write home about.\",\n",
        "        \"Does the job.\",\n",
        "        \"Could be worse.\",\n",
        "        \"It's fine for now.\"\n",
        "    ]\n",
        "\n",
        "    reviews = []\n",
        "\n",
        "    for i in range(count):\n",
        "        product = random.choice(products)\n",
        "\n",
        "        # Distribute sentiments: 40% positive, 35% negative, 25% neutral\n",
        "        sentiment_roll = random.random()\n",
        "        if sentiment_roll < 0.4:\n",
        "            template = random.choice(positive_templates)\n",
        "            emotion = random.choice(emotions_positive)\n",
        "        elif sentiment_roll < 0.75:\n",
        "            template = random.choice(negative_templates)\n",
        "            emotion = random.choice(emotions_negative)\n",
        "        else:\n",
        "            template = random.choice(neutral_templates)\n",
        "            emotion = random.choice(emotions_neutral)\n",
        "\n",
        "        # Select two random feature categories\n",
        "        feature_categories = random.sample(list(features.keys()), 2)\n",
        "        feature1 = random.choice(features[feature_categories[0]])\n",
        "        feature2 = random.choice(features[feature_categories[1]])\n",
        "\n",
        "        review = template.format(\n",
        "            product=product,\n",
        "            feature1=feature1,\n",
        "            feature2=feature2,\n",
        "            emotion=emotion\n",
        "        )\n",
        "\n",
        "        reviews.append(review)\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Generate reviews\n",
        "ALL_REVIEWS = generate_product_reviews(200)\n",
        "print(f\"Generated {len(ALL_REVIEWS)} product reviews\")\n",
        "print(f\"\\nSample reviews:\")\n",
        "for i in range(5):\n",
        "    print(f\"{i+1}. {ALL_REVIEWS[i]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PqBGu5psPs9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Embedding"
      ],
      "metadata": {
        "id": "HNk8LfWCMhDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings for all reviews using Qwen 3 model\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the model\n",
        "embedding_model = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\")\n",
        "\n",
        "def create_embeddings(reviews, batch_size=100):\n",
        "    \"\"\"\n",
        "    Create embeddings for all reviews using OpenAI's embedding model.\n",
        "    Processes in batches to handle rate limits.\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "\n",
        "    print(f\"Creating embeddings for {len(reviews)} reviews...\")\n",
        "\n",
        "    for i in range(0, len(reviews), batch_size):\n",
        "        batch = reviews[i:i + batch_size]\n",
        "        print(f\"Processing batch {i//batch_size + 1}/{(len(reviews)-1)//batch_size + 1}...\")\n",
        "\n",
        "        try:\n",
        "            # response = client.embeddings.create(\n",
        "            #     model=\"text-embedding-3-small\",  # Newer, more efficient model\n",
        "            #     input=batch\n",
        "            # )\n",
        "            # print(f\"Response type: {type(response)}\")\n",
        "            # print(f\"Response: {response}\")\n",
        "\n",
        "            # Extract embeddings from response\n",
        "            batch_embeddings = embedding_model.encode(batch) #[item.embedding for item in response.data]\n",
        "            embeddings.extend(batch_embeddings)\n",
        "\n",
        "            # Small delay to avoid rate limits\n",
        "            if i + batch_size < len(reviews):\n",
        "                time.sleep(0.5)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating embeddings for batch {i//batch_size + 1}: {e}\")\n",
        "            # Fallback: try smaller batch or individual items\n",
        "            for review in batch:\n",
        "                try:\n",
        "                    # response = client.embeddings.create(\n",
        "                    #     model=\"text-embedding-3-small\",\n",
        "                    #     input=[review]\n",
        "                    # )\n",
        "                    # embeddings.append(response.data[0].embedding)\n",
        "                    embedding = embedding_model.encode(review)\n",
        "                    embeddings.append(embedding)\n",
        "                    time.sleep(0.2)\n",
        "                except Exception as e2:\n",
        "                    print(f\"Error creating embedding: {e2}\")\n",
        "                    # Use zero vector as fallback\n",
        "                    embeddings.append([0.0] * 1536)\n",
        "\n",
        "\n",
        "    # Convert to numpy array\n",
        "    embeddings_array = np.array(embeddings, dtype='float32')\n",
        "    print(f\"Created {len(embeddings)} embeddings with dimension {embeddings_array.shape[1]}\")\n",
        "\n",
        "    return embeddings_array\n",
        "\n",
        "# Create embeddings for all reviews\n",
        "review_embeddings = create_embeddings(ALL_REVIEWS)\n",
        "print(f\"\\nEmbeddings shape: {review_embeddings.shape}\")"
      ],
      "metadata": {
        "id": "wNwRDgj_MpmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Index"
      ],
      "metadata": {
        "id": "62_s1aSaMu1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build FAISS index for similarity search\n",
        "import faiss\n",
        "\n",
        "def build_faiss_index(embeddings):\n",
        "    \"\"\"\n",
        "    Build a FAISS index for efficient similarity search.\n",
        "    Uses IndexFlatL2 for exact search (L2 distance).\n",
        "    \"\"\"\n",
        "    dimension = embeddings.shape[1]\n",
        "\n",
        "    # Create FAISS index (using L2 distance for similarity)\n",
        "    index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "    # Add all embeddings to the index\n",
        "    index.add(embeddings)\n",
        "\n",
        "    print(f\"FAISS index created with {index.ntotal} vectors\")\n",
        "    print(f\"Index dimension: {dimension}\")\n",
        "\n",
        "    return index\n",
        "\n",
        "# Build the FAISS index\n",
        "faiss_index = build_faiss_index(review_embeddings)\n",
        "\n",
        "# Store review mapping (index -> review text)\n",
        "review_mapping = {i: review for i, review in enumerate(ALL_REVIEWS)}\n",
        "print(f\"\\nReview mapping created for {len(review_mapping)} reviews\")\n"
      ],
      "metadata": {
        "id": "gWcbPhXlMx4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search Setup"
      ],
      "metadata": {
        "id": "KitGo178NKxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement similarity search function\n",
        "def search_similar_reviews(query, top_k=5):\n",
        "    \"\"\"\n",
        "    Search for similar reviews based on a text query.\n",
        "\n",
        "    Args:\n",
        "        query: Text query to search for\n",
        "        top_k: Number of similar reviews to return\n",
        "\n",
        "    Returns:\n",
        "        List of tuples (review_text, distance, index)\n",
        "    \"\"\"\n",
        "    print(f\"Searching for: '{query}'\")\n",
        "    print(f\"Finding top {top_k} similar reviews...\\n\")\n",
        "\n",
        "    try:\n",
        "        # Create embedding for the query\n",
        "        # response = client.embeddings.create(\n",
        "        #     model=\"text-embedding-3-small\",\n",
        "        #     input=[query]\n",
        "        # )\n",
        "        # query_embedding = np.array([response.data[0].embedding], dtype='float32')\n",
        "\n",
        "        query_embedding = embedding_model.encode(query)\n",
        "\n",
        "        # Search in FAISS index\n",
        "        distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "\n",
        "        # Retrieve the reviews\n",
        "        results = []\n",
        "        for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):\n",
        "            review_text = review_mapping[idx]\n",
        "            results.append((review_text, float(distance), int(idx)))\n",
        "            print(f\"{i+1}. [Distance: {distance:.4f}] {review_text}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during search: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Function to summarize retrieved reviews\n",
        "def summarize_reviews(query, top_k=5, prompting_strategy=\"zero-shot\"):\n",
        "    \"\"\"\n",
        "    Search for similar reviews and generate a summary using specified prompting strategy.\n",
        "\n",
        "    Args:\n",
        "        query: Search query\n",
        "        top_k: Number of similar reviews to retrieve\n",
        "        prompting_strategy: Prompting strategy to use (\"zero-shot\", \"few-shot\", \"chain-of-thought\")\n",
        "\n",
        "    Returns:\n",
        "        Summary text\n",
        "    \"\"\"\n",
        "    # Search for similar reviews\n",
        "    similar_reviews = search_similar_reviews(query, top_k)\n",
        "\n",
        "    if not similar_reviews:\n",
        "        return \"No reviews found.\"\n",
        "\n",
        "    # Prepare reviews text\n",
        "    reviews_text = \"\\n\\n\".join([f\"Review {i+1}: {review[0]}\"\n",
        "                                 for i, review in enumerate(similar_reviews)])\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"SUMMARIZING WITH {prompting_strategy.upper()} PROMPTING\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Choose prompting strategy\n",
        "    if prompting_strategy == \"zero-shot\":\n",
        "        prompt = f\"\"\"Summarize the following product reviews related to '{query}':\n",
        "\n",
        "{reviews_text}\n",
        "\n",
        "Provide a concise summary highlighting the main points, common themes, and overall sentiment.\"\"\"\n",
        "\n",
        "    elif prompting_strategy == \"few-shot\":\n",
        "        prompt = f\"\"\"Summarize the following product reviews:\n",
        "\n",
        "Example 1:\n",
        "Reviews about \"battery issues\":\n",
        "Review 1: Battery dies too quickly\n",
        "Review 2: Charging takes forever\n",
        "Summary: Multiple users report significant battery problems including short battery life and slow charging.\n",
        "\n",
        "Example 2:\n",
        "Reviews about \"great sound\":\n",
        "Review 1: Amazing audio quality!\n",
        "Review 2: Crystal clear sound\n",
        "Summary: Users consistently praise the excellent sound quality and audio clarity.\n",
        "\n",
        "Now summarize these reviews related to '{query}':\n",
        "{reviews_text}\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "    elif prompting_strategy == \"chain-of-thought\":\n",
        "        prompt = f\"\"\"Summarize the following product reviews related to '{query}':\n",
        "\n",
        "{reviews_text}\n",
        "\n",
        "Let's think step by step:\n",
        "1. Identify the main topics mentioned across reviews\n",
        "2. Determine the overall sentiment (positive, negative, or mixed)\n",
        "3. Note any common patterns or recurring issues/praise\n",
        "4. Combine into a clear, concise summary\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "    else:\n",
        "        prompt = f\"Summarize these reviews:\\n\\n{reviews_text}\"\n",
        "\n",
        "    # Generate summary\n",
        "    try:\n",
        "        summary = generate_response(prompt, max_tokens=300)\n",
        "        print(f\"Summary ({prompting_strategy}):\")\n",
        "        print(summary)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating summary: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "yNyz6dnGNOe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search Reviews"
      ],
      "metadata": {
        "id": "d2OCy6WAOO4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo: Test with various queries\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DEMO: VECTOR SEARCH & SUMMARIZATION WITH DIFFERENT PROMPTING STRATEGIES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Test Query 1: Battery life issues\n",
        "print(\"\\n\\n\" + \"🔍 TEST 1: Battery Life Issues\".center(80, \"=\") + \"\\n\")\n",
        "summarize_reviews(\"battery life problems\", top_k=5, prompting_strategy=\"zero-shot\")\n"
      ],
      "metadata": {
        "id": "ZtHVcduPOTzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Query 2: Great sound quality with Few-Shot\n",
        "print(\"\\n\\n\" + \"🔍 TEST 2: Sound Quality (Few-Shot)\".center(80, \"=\") + \"\\n\")\n",
        "summarize_reviews(\"excellent sound quality\", top_k=5, prompting_strategy=\"few-shot\")\n"
      ],
      "metadata": {
        "id": "EL_NiCjjOae9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Query 3: Value for money with Chain-of-Thought\n",
        "print(\"\\n\\n\" + \"🔍 TEST 3: Value for Money (Chain-of-Thought)\".center(80, \"=\") + \"\\n\")\n",
        "summarize_reviews(\"value for money\", top_k=5, prompting_strategy=\"chain-of-thought\")\n"
      ],
      "metadata": {
        "id": "7BAytX7hOdeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Query 4: Durability concerns\n",
        "print(\"\\n\\n\" + \"🔍 TEST 4: Durability Concerns\".center(80, \"=\") + \"\\n\")\n",
        "summarize_reviews(\"durability issues and build quality\", top_k=5, prompting_strategy=\"zero-shot\")\n"
      ],
      "metadata": {
        "id": "ppE91A6uOfUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How This Vector Search System Works\n",
        "\n",
        "**1. Review Generation**: We generated 200 diverse product reviews covering multiple products with varied sentiments and emotional tones.\n",
        "\n",
        "**2. Embedding Creation**: Each review is converted into a vector embedding using OpenAI's text-embedding-3-small model.\n",
        "\n",
        "**3. FAISS Index**: All embeddings are stored in a FAISS index which enables extremely fast similarity search.\n",
        "\n",
        "**4. Semantic Search**: When a user queries, the system converts it to an embedding and finds the most similar reviews.\n",
        "\n",
        "**5. Smart Summarization**: Retrieved reviews are summarized using different prompting strategies (Zero-Shot, Few-Shot, Chain-of-Thought).\n",
        "\n",
        "**Key Benefits**: Fast semantic search, scalable to millions of reviews, flexible prompting strategies."
      ],
      "metadata": {
        "id": "TXyJcEmGPEck"
      }
    }
  ]
}